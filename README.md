# kaggle_titanic

Using ML tools learned recently in courses on the Kaggle Titanic challenge:
===========================================================================

First, tools learned in the Andrew Ng Coursera Machine Learning course offered by Stanford.   (Octave Gnu)
https://www.coursera.org/learn/machine-learning/home/welcome

| Algorithm | Score |
|-----------|-------|
|  Support Vector Machine         |  0.78947    | 
|  Logistic Regression        |    0.76315   | 
|   Neural Network:        |       | 
|    - 7x7 lambda 0.005      |   0.75358    | 
|      - 7x2 lambda 0.3     |   0.77990   | 

Second, tools from Machine Learning A-ZÂª: Hands-On Python & R In Data Science
(Python, Jupyter Notebooks)
https://www.udemy.com/course/machinelearning/


| Algorithm                     | Score   |
|-------------------------------|---------|
| Kernel Support Vector Machine |         |
| - linear                      | 0.76555 |
| - rbf                         | 0.78229 |
| - poly                        | 0.76794 |
| - sigmoid                     | 0.63875 |
| Decision Tree                 |         |
| - entropy                     | 0.72488 |
| - gini                        | 0.70574 |
| Naive Bayes                   | 0.74401 |
| Random Forest                 | 0.76076 |
| CatBoost                      | 0.76794 |
| Neural nets:                  |         |
| - 7x2 adam                    | 0.76794 |
| - 7x2 rmsprop                 | 0.77272 |
| - 7x4 adam                    |  0.75837 |
| - 7x4 nadam                   | 0.77511 |


